# Evaluation of targeted dataset collection on racial equity in face recognition

## Final Manuscript

[temporary] Find the published paper here: https://github.com/hongrachel/representation-disparities/blob/main/final-manuscript.pdf

Please cite our work as follows:

```
@inproceedings{hong2023evaluation,
  title={Evaluation of targeted dataset collection on racial equity in face recognition},
  author={Hong, Rachel and Kohno, Tadayoshi and Morgenstern, Jamie},
  publisher = {ACM},
  address = {New York, NY, USA},
  booktitle={Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society},
  year={2023}
}
```

## Setup

Run `pip install --upgrade pip`.

Install necessary packages: `pip install -r requirements.txt`.

## Datasets

Download `BUPT-Balancedface`: http://www.whdeng.cn/RFW/Trainingdataste.html.
Download `RFW`: http://www.whdeng.cn/RFW/testing.html.

Download `BFW`: https://github.com/visionjo/facerec-bias-bfw

Download `VMER`: first download VGGFace2: https://www.robots.ox.ac.uk/~vgg/data/vgg_face2/, then download the racial group annotations: https://mivia.unisa.it/ethnicity-recognition-dataset/

To evaluate on BUPT, BFW, or VMER datasets, modify the paths in `configs/*_data.py` according to wherever you put the datasets. `configs/points_*.json` give all training configurations based on the total dataset size per group. These json files are generated by `scripts/make_*_points_config.py` files.

## New datasets

Add a new config (`[your name]_data.py`) to `configs/`, and add branch logic to `main.py:get_data_config()` such that your config will be loaded.

Create the corresponding `configs/points_*.json` file for all training configurations using `scripts/make_*_points_config.py`.

Add a model file to `data/` (`[your name].py`) which retrieves and pre-processes the image files from the `configs/*_data.py` paths to feed into the model for both training and test.

## Experiments

Bash scripts that create the job array files to run our experiments can be found under the `experiments` directory. `1_to_2_increase_race_simplex.sh` replicates the single-group augmentation method by holding the samples from one group fixed as additional data is introduced from another group. `pair_race_simplex.sh` creates all possible size combinations from any two groups.

Note that you will need to finish all setup steps before running an experiment!

The settings given in the `experiments` and `configs` directories will reproduce our experimental results, as reported in the paper.

These can also be modified to use our single-group augmentation framework for any other dataset with racial group annotations or model.

## References

Much of our codebase is based on https://github.com/j-alex-hanson/rethinking-race-face-datasets in Gwilliam et al, 2021.

[1] Q. Cao, L. Shen, W. Xie, O. M. Parkhi, A. Zisserman. VGGFace2: A dataset for recognising faces across pose and age. In FG 2018.

[2] M. Gwilliam, S. Hegde, L. Tinubu, and A. Hanson. Rethinking Common Assumptions to Mitigate Racial Bias in Face Recognition Datasets. In ICCV 2021.

[3] J. Robinson, G. Livitz, Y. Henon, C. Qin, Y. Fu, and S. Timoner. Face recognition: too bias, or not too bias? In CVPR 2020.

[4] M. Wang and W. Deng. Mitigating bias in face recognition using skewness-aware reinforcement learning. In CVPR 2020.

[5] M. Wang, W. Deng, J. Hu, X. Tao, and Y. Huang. Racial Faces in the Wild: Reducing Racial Bias by Information Maximization Adaptation Network. In ICCV 2019.
